![Autodistill banner](https://camo.githubusercontent.com/2a4712931b5698aca7a95dfd90eb56a693fe59320eee64c1897042d5c3c21959/68747470733a2f2f6d656469612e726f626f666c6f772e636f6d2f6f70656e2d736f757263652f6175746f64697374696c6c2f6175746f64697374696c6c2d62616e6e65722e706e67)

# üëã Welcome 

`autodistill` is a Python package to distill large foundational models into smaller, domain-specific models for deployment. Using autodistill, you can go from images to inference on a custom model with little to no labeling in between for a range of use cases.

Distilled models are smaller than general vision models and easier to refine and fine-tune to the situation in which your model will be deployed.

## üíª Installation

To install `autodistill`, run the following command:

```bash
pip install autodistill
```

You can also clone the project from GitHub for local development:

```bash
git clone https://github.com/roboflow/autodistill
cd autodistill
pip install -e .
```

## üöÄ Quickstart

See the [Quickstart.ipynb](Quickstart.ipynb) notebook for a quick introduction to `autodistill`. Below, we have condensed key parts of the notebook for a quick introduction to `autodistill`.

### Install Packages

For this example, we'll show how to distill Grounded SAM into a small YOLOv8 model.

```
pip install autodistill autodistill-grounded-sam autodistill-yolov8
```

### Distill a Model

```python
from autodistill_grounded_sam import GroundedSAM
from autodistill.detection import CaptionOntology
from autodistill_yolov8 import YOLOv8
import supervision as sv
import os

# define an ontology to map class names to our GroundingDINO prompt
# the ontology dictionary has the format {caption: class}
# where caption is the prompt sent to the base model, and class is the label that will
# be saved for that caption in the generated annotations
# then, load the model
base_model = GroundedSAM(ontology=CaptionOntology({"shipping container": "container"}))

# make a list of classes for use in plotting
classes = ["container"]

# load the base model and set the ontology
base_model = GroundingDINO(ontology)
base_model.set_ontology(ontology)

# label all images in a folder called `context_images`
base_model.label("./context_images", extension=".jpeg")

target_model = YOLOv8("yolov8n.pt")
target_model.train("./context_images_labeled/data.yaml", epochs=200)

# run inference on the new model
pred = target_model.predict("./context_images_labeled/train/images/dog-7.jpg", conf=0.01)

# optional: upload your model to Roboflow for deployment
from roboflow import Roboflow

rf = Roboflow(api_key="API_KEY")
project = rf.workspace().project("PROJECT_ID")
project.version(DATASET_VERSION).deploy(model_type="yolov8", model_path=f"{HOME}/runs/detect/train/")
```

`base_models` are models that have been pre-trained to have a wide breadth of knowledge. 

Base models have `ontologies` which are the prompts we can use to draw predictions from them. Deciding the proper ontology (and installing your CUDA drivers) is most of the work you will have to do to train distilled models with autodistill.

To distill a model, you will need to bring example data of the context you want to your model to operate in.

`target_models` are smaller in-domain models that you will train using the annotations generated by your base model. 

See the section below for information on supported models.

### Annotate a Single Image

To plot the annotations for a single image using `autodistill`, you can use the code below. This code is helpful to visualize the annotations generated by your base model (i.e. Grounding DINO) and the results from your target model (i.e. YOLOv8).

```python
import supervision as sv
import cv2

img_path = "./context_images/dog.jpeg"

image = cv2.imread(img_path)

detections = base_model.predict(img_path)
# annotate image with detections
box_annotator = sv.BoxAnnotator()

labels = [
    f"{base_model.ontology.class_id_map[class_id]} {confidence:0.2f}"
    for _, _, confidence, class_id, _ in detections
]

annotated_frame = box_annotator.annotate(
    scene=image.copy(), detections=detections, labels=labels
)

sv.plot_image(annotated_frame, (16, 16))
```

## üîé Supported Models

Autodistill currently supports using the following models as base models (the models you will use to label images for your new model):

- Grounded SAM

The following target models are supported:

- YOLOv8
- YOLOv8 Instance Segmentation

Refer to the [project README](https://github.com/roboflow/autodistill/blob/main/README.md) for our roadmap on adding more models.

## ‚ö†Ô∏è Limitations

Before running `autodistill` on a full dataset, we recommend testing with a few images to ensure your prompt identifies objects as expected.

Grounding DINO is not effective at identifying the differences between classes that are mostly used in the same contexts in language.

For instance, Grounding DINO can accurately identify a cat vs. a dog. But, Grounding DINO struggles with "cup" vs. "bottle".